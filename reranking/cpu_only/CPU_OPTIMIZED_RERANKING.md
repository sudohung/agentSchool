# ğŸ’» CPU-onlyç¯å¢ƒä¸‹çš„é‡æ’ä¼˜åŒ–æ–¹æ¡ˆ

åœ¨ä¸ªäººç”µè„‘çš„CPU-onlyç¯å¢ƒä¸‹ï¼Œæˆ‘ä»¬éœ€è¦ç‰¹åˆ«è€ƒè™‘è®¡ç®—èµ„æºé™åˆ¶ï¼Œé€‰æ‹©è½»é‡çº§ä½†æœ‰æ•ˆçš„é‡æ’æ–¹æ¡ˆã€‚

## ğŸ¯ CPUç¯å¢ƒä¼˜åŒ–åŸåˆ™

### æ ¸å¿ƒçº¦æŸæ¡ä»¶
- **å†…å­˜é™åˆ¶**: é€šå¸¸4-16GB RAM
- **è®¡ç®—èƒ½åŠ›**: æ— GPUåŠ é€Ÿï¼Œä¾èµ–CPUå¤šæ ¸å¤„ç†
- **å“åº”æ—¶é—´**: ç”¨æˆ·å¯æ¥å—çš„å»¶è¿Ÿ(<1ç§’)
- **æ¨¡å‹å¤§å°**: é¿å…è¿‡å¤§æ¨¡å‹å¯¼è‡´å†…å­˜æº¢å‡º

### ä¼˜åŒ–ç›®æ ‡ä¼˜å…ˆçº§
1. **æ¨ç†é€Ÿåº¦** > æ¨¡å‹ç²¾åº¦
2. **å†…å­˜æ•ˆç‡** > æ¨¡å‹å¤æ‚åº¦  
3. **å®ç”¨æ€§** > ç†è®ºæœ€ä¼˜
4. **æ˜“éƒ¨ç½²** > åŠŸèƒ½ä¸°å¯Œ

## ğŸš€ è½»é‡çº§é‡æ’æ¨¡å‹æ¨è

### 1. CPUå‹å¥½çš„åµŒå…¥æ¨¡å‹

#### A. MiniLMç³»åˆ— (æ¨èæŒ‡æ•°: â­â­â­â­â­)
```python
# æœ€é€‚åˆCPUçš„è½»é‡çº§æ¨¡å‹
models_cpu_friendly = {
    'all-MiniLM-L6-v2': {
        'å‚æ•°é‡': 22M,
        'ç»´åº¦': 384,
        'å†…å­˜å ç”¨': ~100MB,
        'ç‰¹ç‚¹': 'è‹±æ–‡ä¼˜åŒ–ï¼Œé€Ÿåº¦æå¿«'
    },
    'paraphrase-multilingual-MiniLM-L12-v2': {
        'å‚æ•°é‡': 118M,
        'ç»´åº¦': 384, 
        'å†…å­˜å ç”¨': ~400MB,
        'ç‰¹ç‚¹': 'å¤šè¯­è¨€æ”¯æŒï¼Œå¹³è¡¡æ€§èƒ½'
    },
    'bge-small-en-v1.5': {
        'å‚æ•°é‡': 33M,
        'ç»´åº¦': 384,
        'å†…å­˜å ç”¨': ~150MB,
        'ç‰¹ç‚¹': 'è‹±æ–‡ä¸“ç”¨ï¼Œæ•ˆæœä¼˜ç§€'
    }
}
```

#### B. TinyBERTç³»åˆ—
```python
# è¶…è½»é‡çº§é€‰é¡¹
class CPUEfficientModels:
    def __init__(self):
        # TinyBERTæ¨¡å‹ï¼Œä¸“ä¸ºCPUä¼˜åŒ–
        self.tiny_bert_models = {
            'tinybert-4l-312d': {
                'å±‚æ•°': 4,
                'éšè—å±‚': 312,
                'æ¨ç†é€Ÿåº¦': 'æå¿«',
                'å†…å­˜': '~50MB'
            },
            'tinybert-6l-768d': {
                'å±‚æ•°': 6, 
                'éšè—å±‚': 768,
                'æ¨ç†é€Ÿåº¦': 'å¾ˆå¿«',
                'å†…å­˜': '~150MB'
            }
        }
```

### 2. è½»é‡çº§é‡æ’å™¨å®ç°

#### A. åŸºäºè§„åˆ™çš„å¿«é€Ÿé‡æ’
```python
class RuleBasedReranker:
    """åŸºäºè§„åˆ™çš„è½»é‡çº§é‡æ’å™¨"""
    
    def __init__(self):
        self.weights = {
            'bm25_score': 0.4,
            'popularity': 0.2,
            'recency': 0.2, 
            'length_match': 0.2
        }
    
    def rerank(self, query, candidates):
        """å¿«é€Ÿè§„åˆ™é‡æ’"""
        scored_candidates = []
        
        for candidate in candidates:
            # BM25å¯å‘å¼è¯„åˆ†
            bm25_score = self._bm25_score(query, candidate.content)
            
            # æµè¡Œåº¦è¯„åˆ†
            popularity_score = candidate.features.get('popularity', 0.5)
            
            # æ—¶æ•ˆæ€§è¯„åˆ†
            recency_score = candidate.features.get('recency', 0.5)
            
            # é•¿åº¦åŒ¹é…åº¦
            length_score = self._length_matching(query, candidate.content)
            
            # åŠ æƒèåˆ
            final_score = (
                self.weights['bm25_score'] * bm25_score +
                self.weights['popularity'] * popularity_score +
                self.weights['recency'] * recency_score +
                self.weights['length_match'] * length_score
            )
            
            scored_candidates.append((final_score, candidate))
        
        # æ’åºè¿”å›
        return sorted(scored_candidates, key=lambda x: x[0], reverse=True)
    
    def _bm25_score(self, query, document):
        """è½»é‡çº§BM25å®ç°"""
        query_terms = query.lower().split()
        doc_terms = document.lower().split()
        
        k1, b = 1.2, 0.75
        avg_doc_len = 100  # é¢„ä¼°å¹³å‡æ–‡æ¡£é•¿åº¦
        doc_len = len(doc_terms)
        
        score = 0
        for term in query_terms:
            tf = doc_terms.count(term)
            if tf > 0:
                # ç®€åŒ–ç‰ˆIDFè®¡ç®—
                idf = np.log(1000 / (tf + 0.5))
                numerator = tf * (k1 + 1)
                denominator = tf + k1 * (1 - b + b * doc_len / avg_doc_len)
                score += idf * numerator / denominator
        
        return min(1.0, score)  # å½’ä¸€åŒ–åˆ°0-1
    
    def _length_matching(self, query, document):
        """é•¿åº¦åŒ¹é…åº¦è®¡ç®—"""
        query_len = len(query)
        doc_len = len(document)
        ratio = min(query_len, doc_len) / max(query_len, doc_len)
        return ratio
```

#### B. è½»é‡çº§æœºå™¨å­¦ä¹ é‡æ’
```python
class LightweightMLReranker:
    """è½»é‡çº§æœºå™¨å­¦ä¹ é‡æ’å™¨"""
    
    def __init__(self):
        # ä½¿ç”¨è½»é‡çº§æ¨¡å‹
        self.model = None
        self.feature_scaler = StandardScaler()
        self.is_trained = False
    
    def train_lightweight(self, training_data):
        """è®­ç»ƒè½»é‡çº§æ¨¡å‹"""
        # ä½¿ç”¨çº¿æ€§æ¨¡å‹æˆ–å°è§„æ¨¡éšæœºæ£®æ—
        from sklearn.linear_model import LogisticRegression
        # æˆ–è€…éå¸¸å°çš„éšæœºæ£®æ—
        from sklearn.ensemble import RandomForestClassifier
        
        self.model = LogisticRegression(max_iter=1000)
        # self.model = RandomForestClassifier(n_estimators=10, max_depth=5)
        
        # ç‰¹å¾å·¥ç¨‹ä¿æŒç®€å•
        X, y = self._extract_simple_features(training_data)
        X_scaled = self.feature_scaler.fit_transform(X)
        
        self.model.fit(X_scaled, y)
        self.is_trained = True
    
    def _extract_simple_features(self, training_data):
        """æå–ç®€å•ç‰¹å¾ä»¥å‡å°‘è®¡ç®—è´Ÿæ‹…"""
        X, y = [], []
        
        for query, docs, labels in training_data:
            for doc, label in zip(docs, labels):
                features = [
                    len(set(query.split()) & set(doc.content.split())),  # è¯æ±‡é‡å 
                    len(doc.content) / (len(query) + 1),  # é•¿åº¦æ¯”ä¾‹
                    doc.features.get('popularity', 0.5),  # æµè¡Œåº¦
                    self._simple_similarity(query, doc.content)  # ç®€å•ç›¸ä¼¼åº¦
                ]
                X.append(features)
                y.append(label)
        
        return np.array(X), np.array(y)
    
    def _simple_similarity(self, text1, text2):
        """ç®€å•çš„æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—"""
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        if not words1 or not words2:
            return 0
        return len(words1 & words2) / len(words1 | words2)
```

## âš¡ CPUä¼˜åŒ–æŠ€æœ¯

### 1. æ‰¹é‡å¤„ç†ä¼˜åŒ–
```python
class CPUBatchProcessor:
    """CPUæ‰¹é‡å¤„ç†ä¼˜åŒ–å™¨"""
    
    def __init__(self, batch_size=32):
        self.batch_size = batch_size
        self.thread_pool = ThreadPoolExecutor(max_workers=4)  # æ ¹æ®CPUæ ¸å¿ƒæ•°è°ƒæ•´
    
    def batch_encode(self, texts, model):
        """æ‰¹é‡ç¼–ç ä¼˜åŒ–"""
        results = []
        
        # åˆ†æ‰¹å¤„ç†é¿å…å†…å­˜å³°å€¼
        for i in range(0, len(texts), self.batch_size):
            batch = texts[i:i + self.batch_size]
            
            # å¹¶è¡Œå¤„ç†æ‰¹æ¬¡
            batch_result = model.encode(batch, show_progress_bar=False)
            results.extend(batch_result)
            
            # é€‚æ—¶é‡Šæ”¾å†…å­˜
            if i % (self.batch_size * 4) == 0:
                import gc
                gc.collect()
        
        return np.array(results)
    
    def parallel_rerank(self, queries, candidates_list, reranker):
        """å¹¶è¡Œé‡æ’å¤„ç†"""
        futures = []
        
        # æäº¤å¹¶è¡Œä»»åŠ¡
        for query, candidates in zip(queries, candidates_list):
            future = self.thread_pool.submit(reranker.rerank, query, candidates)
            futures.append(future)
        
        # æ”¶é›†ç»“æœ
        results = [future.result() for future in futures]
        return results
```

### 2. å†…å­˜ä¼˜åŒ–ç­–ç•¥
```python
class MemoryEfficientReranker:
    """å†…å­˜é«˜æ•ˆé‡æ’å™¨"""
    
    def __init__(self):
        self.model_cache = {}
        self.max_cache_size = 1000
    
    def memory_efficient_rerank(self, query, candidates):
        """å†…å­˜å‹å¥½çš„é‡æ’å®ç°"""
        # 1. æµå¼å¤„ç†é¿å…åŠ è½½å…¨éƒ¨æ•°æ®
        processed_candidates = []
        
        for candidate in candidates:
            # é€ä¸ªå¤„ç†ï¼ŒåŠæ—¶é‡Šæ”¾ä¸­é—´ç»“æœ
            score = self._compute_score_efficiently(query, candidate)
            processed_candidates.append((score, candidate))
            
            # å®šæœŸæ¸…ç†ä¸éœ€è¦çš„å¯¹è±¡
            if len(processed_candidates) % 50 == 0:
                self._cleanup_memory()
        
        # 2. ä½¿ç”¨å°±åœ°æ’åºèŠ‚çœå†…å­˜
        processed_candidates.sort(key=lambda x: x[0], reverse=True)
        return processed_candidates
    
    def _compute_score_efficiently(self, query, candidate):
        """å†…å­˜é«˜æ•ˆçš„åˆ†æ•°è®¡ç®—"""
        # é¿å…åˆ›å»ºå¤§çš„ä¸­é—´æ•°ç»„
        query_words = query.lower().split()
        doc_words = candidate.content.lower().split()
        
        # ä½¿ç”¨é›†åˆæ“ä½œè€Œä¸æ˜¯å¾ªç¯
        overlap = len(set(query_words) & set(doc_words))
        total_unique = len(set(query_words) | set(doc_words))
        
        return overlap / total_unique if total_unique > 0 else 0
    
    def _cleanup_memory(self):
        """å†…å­˜æ¸…ç†"""
        import gc
        # æ¸…ç†ç¼“å­˜ä¸­è¾ƒå°‘ä½¿ç”¨çš„é¡¹
        if len(self.model_cache) > self.max_cache_size:
            # ç§»é™¤æœ€è€çš„ç¼“å­˜é¡¹
            oldest_key = next(iter(self.model_cache))
            del self.model_cache[oldest_key]
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()
```

### 3. æ¨¡å‹é‡åŒ–å’Œå‹ç¼©
```python
class QuantizedReranker:
    """é‡åŒ–é‡æ’å™¨"""
    
    def __init__(self):
        self.quantized_model = None
    
    def quantize_model(self, original_model):
        """æ¨¡å‹é‡åŒ–ä»¥å‡å°‘å†…å­˜å ç”¨"""
        # ç®€å•çš„8ä½é‡åŒ–ç¤ºä¾‹
        def quantize_weights(weights):
            # å°†æµ®ç‚¹æ•°æƒé‡è½¬æ¢ä¸º8ä½æ•´æ•°
            min_val, max_val = weights.min(), weights.max()
            scale = (max_val - min_val) / 255.0
            zero_point = -min_val / scale
            quantized = np.round(weights / scale + zero_point).astype(np.uint8)
            return quantized, scale, zero_point
        
        # å¯¹æ¨¡å‹æƒé‡è¿›è¡Œé‡åŒ–
        quantized_weights = {}
        scales = {}
        zero_points = {}
        
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…éœ€è¦éå†æ¨¡å‹æ‰€æœ‰å±‚
        # quantized_weights[layer_name], scales[layer_name], zero_points[layer_name] = \
        #     quantize_weights(original_model.get_layer(layer_name).get_weights())
        
        self.quantized_model = {
            'weights': quantized_weights,
            'scales': scales,
            'zero_points': zero_points
        }
        
        return self.quantized_model
    
    def dequantize_and_predict(self, quantized_input):
        """åé‡åŒ–å¹¶é¢„æµ‹"""
        # åé‡åŒ–è¿‡ç¨‹
        # è¿™æ˜¯ç®€åŒ–çš„ç¤ºä¾‹ï¼Œå®é™…å®ç°éœ€è¦æ ¹æ®å…·ä½“æ¨¡å‹ç»“æ„è°ƒæ•´
        pass
```

## ğŸ“Š CPUç¯å¢ƒä¸‹çš„æ€§èƒ½åŸºå‡†

### æ¨èé…ç½®ç»„åˆ

#### å…¥é—¨çº§é…ç½® (4GB RAM, åŒæ ¸CPU)
```python
config_entry_level = {
    'model': 'all-MiniLM-L6-v2',  # æœ€è½»é‡æ¨¡å‹
    'batch_size': 16,             # å°æ‰¹æ¬¡
    'max_candidates': 100,        # é™åˆ¶å€™é€‰æ•°é‡
    'reranker': 'rule_based',     # åŸºäºè§„åˆ™çš„é‡æ’
    'expected_latency': '<200ms'  # é¢„æœŸå»¶è¿Ÿ
}
```

#### æ ‡å‡†çº§é…ç½® (8GB RAM, å››æ ¸CPU)
```python
config_standard = {
    'model': 'paraphrase-multilingual-MiniLM-L12-v2',
    'batch_size': 32,
    'max_candidates': 500,
    'reranker': 'lightweight_ml',
    'expected_latency': '<500ms'
}
```

#### é«˜æ€§èƒ½é…ç½® (16GB+ RAM, å…«æ ¸CPU)
```python
config_high_performance = {
    'model': 'bge-small-en-v1.5',
    'batch_size': 64,
    'max_candidates': 1000,
    'reranker': 'hybrid_approach',  # æ··åˆæ–¹æ³•
    'expected_latency': '<800ms'
}
```

### æ€§èƒ½æµ‹è¯•ä»£ç 
```python
class CPUPerformanceBenchmark:
    """CPUæ€§èƒ½åŸºå‡†æµ‹è¯•"""
    
    def benchmark_configurations(self):
        """æµ‹è¯•ä¸åŒé…ç½®çš„æ€§èƒ½"""
        configs = [
            ('å…¥é—¨çº§', config_entry_level),
            ('æ ‡å‡†çº§', config_standard), 
            ('é«˜æ€§èƒ½', config_high_performance)
        ]
        
        results = {}
        
        for config_name, config in configs:
            print(f"æµ‹è¯• {config_name} é…ç½®...")
            
            # åˆå§‹åŒ–å¯¹åº”é…ç½®çš„é‡æ’å™¨
            reranker = self._initialize_reranker(config)
            
            # è¿è¡ŒåŸºå‡†æµ‹è¯•
            metrics = self._run_benchmark(reranker, config)
            results[config_name] = metrics
            
            print(f"  å¤„ç†æ—¶é—´: {metrics['processing_time']:.3f}s")
            print(f"  å†…å­˜ä½¿ç”¨: {metrics['memory_usage']:.1f}MB")
            print(f"  å‡†ç¡®ç‡: {metrics['accuracy']:.3f}")
            print("-" * 30)
        
        return results
    
    def _initialize_reranker(self, config):
        """æ ¹æ®é…ç½®åˆå§‹åŒ–é‡æ’å™¨"""
        if config['reranker'] == 'rule_based':
            return RuleBasedReranker()
        elif config['reranker'] == 'lightweight_ml':
            return LightweightMLReranker()
        else:
            return HybridReranker()
    
    def _run_benchmark(self, reranker, config):
        """è¿è¡ŒåŸºå‡†æµ‹è¯•"""
        import psutil
        import time
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        test_data = self._generate_test_data(config['max_candidates'])
        
        # è®°å½•åˆå§‹å†…å­˜
        process = psutil.Process()
        initial_memory = process.memory_info().rss / 1024 / 1024
        
        # æ‰§è¡Œé‡æ’
        start_time = time.time()
        results = reranker.rerank("æµ‹è¯•æŸ¥è¯¢", test_data)
        processing_time = time.time() - start_time
        
        # è®°å½•æœ€ç»ˆå†…å­˜
        final_memory = process.memory_info().rss / 1024 / 1024
        memory_usage = final_memory - initial_memory
        
        # ç®€å•çš„å‡†ç¡®ç‡è¯„ä¼°
        accuracy = self._evaluate_accuracy(results)
        
        return {
            'processing_time': processing_time,
            'memory_usage': memory_usage,
            'accuracy': accuracy
        }
```

## ğŸ”§ å®ç”¨ä¼˜åŒ–æŠ€å·§

### 1. ç¼“å­˜ç­–ç•¥
```python
class SmartCacheReranker:
    """æ™ºèƒ½ç¼“å­˜é‡æ’å™¨"""
    
    def __init__(self, cache_size=1000):
        self.cache = {}
        self.cache_size = cache_size
        self.access_count = {}
    
    def cached_rerank(self, query, candidates):
        """å¸¦ç¼“å­˜çš„é‡æ’"""
        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = self._generate_cache_key(query, candidates)
        
        # æ£€æŸ¥ç¼“å­˜
        if cache_key in self.cache:
            self.access_count[cache_key] = self.access_count.get(cache_key, 0) + 1
            return self.cache[cache_key]
        
        # è®¡ç®—ç»“æœ
        result = self._compute_rerank(query, candidates)
        
        # æ›´æ–°ç¼“å­˜
        self._update_cache(cache_key, result)
        
        return result
    
    def _generate_cache_key(self, query, candidates):
        """ç”Ÿæˆç¼“å­˜é”®"""
        # ä½¿ç”¨æŸ¥è¯¢å’Œå€™é€‰æ–‡æ¡£çš„å“ˆå¸Œå€¼
        candidate_ids = [c.doc_id for c in candidates]
        return hash((query, tuple(sorted(candidate_ids))))
    
    def _update_cache(self, key, value):
        """æ›´æ–°ç¼“å­˜ï¼Œå®ç°LRUæ·˜æ±°"""
        if len(self.cache) >= self.cache_size:
            # ç§»é™¤æœ€å°‘è®¿é—®çš„é¡¹
            lru_key = min(self.access_count.keys(), key=lambda k: self.access_count[k])
            del self.cache[lru_key]
            del self.access_count[lru_key]
        
        self.cache[key] = value
        self.access_count[key] = 1
```

### 2. æ¸è¿›å¼å¤„ç†
```python
class ProgressiveReranker:
    """æ¸è¿›å¼é‡æ’å™¨"""
    
    def __init__(self):
        self.stages = [
            ('fast_filter', 0.3),    # å¿«é€Ÿè¿‡æ»¤æ‰30%æ˜æ˜¾ä¸ç›¸å…³çš„
            ('medium_rerank', 0.6),  # ä¸­ç­‰å¤æ‚åº¦é‡æ’å‰©ä½™60%
            ('final_polish', 1.0)    # ç²¾ç»†é‡æ’æœ€ç»ˆ100%
        ]
    
    def progressive_rerank(self, query, candidates):
        """æ¸è¿›å¼é‡æ’å¤„ç†"""
        current_candidates = candidates
        
        for stage_name, keep_ratio in self.stages:
            # æ ¹æ®é˜¶æ®µé€‰æ‹©ä¸åŒçš„é‡æ’ç­–ç•¥
            if stage_name == 'fast_filter':
                current_candidates = self._fast_filter(query, current_candidates, keep_ratio)
            elif stage_name == 'medium_rerank':
                current_candidates = self._medium_rerank(query, current_candidates, keep_ratio)
            else:  # final_polish
                current_candidates = self._final_rerank(query, current_candidates)
        
        return current_candidates
    
    def _fast_filter(self, query, candidates, keep_ratio):
        """å¿«é€Ÿè¿‡æ»¤é˜¶æ®µ"""
        # ä½¿ç”¨ç®€å•çš„è¯é¢‘ç»Ÿè®¡å¿«é€Ÿè¿‡æ»¤
        scored = []
        for candidate in candidates:
            score = self._simple_relevance_score(query, candidate.content)
            scored.append((score, candidate))
        
        # ä¿ç•™top-k
        k = int(len(candidates) * keep_ratio)
        return [candidate for score, candidate in sorted(scored, reverse=True)[:k]]
    
    def _medium_rerank(self, query, candidates, keep_ratio):
        """ä¸­ç­‰å¤æ‚åº¦é‡æ’"""
        # ä½¿ç”¨è½»é‡çº§ç‰¹å¾å·¥ç¨‹
        # å®ç°ç•¥...
        pass
    
    def _final_rerank(self, query, candidates):
        """æœ€ç»ˆç²¾ç»†åŒ–é‡æ’"""
        # ä½¿ç”¨ç›¸å¯¹å¤æ‚çš„æ¨¡å‹è¿›è¡Œæœ€ç»ˆæ’åº
        # å®ç°ç•¥...
        pass
```

## ğŸ¯ æœ€ä½³å®è·µå»ºè®®

### é…ç½®é€‰æ‹©æŒ‡å—
1. **å†…å­˜ â‰¤ 4GB**: ä½¿ç”¨å…¥é—¨çº§é…ç½® + è§„åˆ™é‡æ’
2. **å†…å­˜ 4-8GB**: ä½¿ç”¨æ ‡å‡†çº§é…ç½® + è½»é‡MLé‡æ’  
3. **å†…å­˜ 8-16GB**: ä½¿ç”¨é«˜æ€§èƒ½é…ç½® + æ··åˆé‡æ’
4. **å†…å­˜ > 16GB**: å¯ä»¥è€ƒè™‘æ›´å¤æ‚çš„æ¨¡å‹

### æ€§èƒ½ä¼˜åŒ–è¦ç‚¹
- âœ… ä¼˜å…ˆä½¿ç”¨è½»é‡çº§é¢„è®­ç»ƒæ¨¡å‹
- âœ… å®æ–½åˆç†çš„æ‰¹é‡å¤„ç†ç­–ç•¥
- âœ… ä½¿ç”¨æ™ºèƒ½ç¼“å­˜å‡å°‘é‡å¤è®¡ç®—
- âœ… å®æ–½æ¸è¿›å¼å¤„ç†é¿å…ä¸€æ¬¡æ€§å¤§é‡è®¡ç®—
- âœ… å®šæœŸè¿›è¡Œå†…å­˜æ¸…ç†å’Œåƒåœ¾å›æ”¶

### ç›‘æ§å’Œè°ƒè¯•
```python
class CPUMonitor:
    """CPUç¯å¢ƒç›‘æ§å™¨"""
    
    def monitor_performance(self, reranker, test_queries):
        """ç›‘æ§é‡æ’æ€§èƒ½"""
        metrics = {
            'avg_processing_time': [],
            'memory_usage': [],
            'accuracy_scores': []
        }
        
        for query in test_queries:
            # ç›‘æ§å¤„ç†æ—¶é—´
            start_time = time.time()
            result = reranker.rerank(query, self.sample_candidates)
            processing_time = time.time() - start_time
            metrics['avg_processing_time'].append(processing_time)
            
            # ç›‘æ§å†…å­˜ä½¿ç”¨
            memory_mb = psutil.Process().memory_info().rss / 1024 / 1024
            metrics['memory_usage'].append(memory_mb)
            
            # ç®€å•çš„å‡†ç¡®ç‡è¯„ä¼°
            accuracy = self._simple_accuracy_check(result)
            metrics['accuracy_scores'].append(accuracy)
        
        return self._summarize_metrics(metrics)
```

è®°ä½ï¼šåœ¨CPU-onlyç¯å¢ƒä¸‹ï¼Œå®ç”¨æ€§å¾€å¾€æ¯”ç†è®ºæœ€ä¼˜æ›´é‡è¦ï¼