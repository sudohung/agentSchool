"""
å‘é‡æ•°æ®åº“å’ŒåµŒå…¥æ¨¡å‹å®æˆ˜ç¤ºä¾‹
Vector Database and Embedding Model Practical Examples
"""

import numpy as np
from sentence_transformers import SentenceTransformer
import faiss
import time

class VectorDBDemo:
    """å‘é‡æ•°æ®åº“æ¼”ç¤ºç±»"""
    
    def __init__(self, model_name='paraphrase-multilingual-MiniLM-L12-v2'):
        """åˆå§‹åŒ–åµŒå…¥æ¨¡å‹"""
        print("ğŸš€ åˆå§‹åŒ–åµŒå…¥æ¨¡å‹...")
        self.model = SentenceTransformer(model_name)
        print(f"âœ… æ¨¡å‹ '{model_name}' åŠ è½½å®Œæˆ")
        
    def text_to_vectors(self, texts):
        """å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡"""
        print(f"\nğŸ“ å°† {len(texts)} æ¡æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡...")
        start_time = time.time()
        vectors = self.model.encode(texts)
        end_time = time.time()
        
        print(f"âœ… è½¬æ¢å®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f} ç§’")
        print(f"ğŸ“Š å‘é‡ç»´åº¦: {len(vectors[0])}")
        print(f"ğŸ“Š å‘é‡æ•°é‡: {len(vectors)}")
        
        return vectors
    
    def create_vector_db(self, vectors):
        """åˆ›å»ºå‘é‡æ•°æ®åº“"""
        print("\nğŸ—„ï¸ åˆ›å»ºå‘é‡æ•°æ®åº“...")
        dimension = len(vectors[0])
        
        # ä½¿ç”¨ L2 è·ç¦»çš„å¹³é¢ç´¢å¼•
        index = faiss.IndexFlatL2(dimension)
        index.add(np.array(vectors))
        
        print(f"âœ… å‘é‡æ•°æ®åº“åˆ›å»ºå®Œæˆ")
        print(f"ğŸ“Š æ•°æ®åº“å­˜å‚¨å‘é‡æ•°: {index.ntotal}")
        
        return index
    
    def search_similar(self, index, query_text, texts, k=3):
        """æœç´¢ç›¸ä¼¼æ–‡æœ¬"""
        print(f"\nğŸ” æœç´¢ä¸ '{query_text}' ç›¸ä¼¼çš„æ–‡æœ¬...")
        
        # å°†æŸ¥è¯¢æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡
        query_vector = self.model.encode([query_text])
        
        # æ‰§è¡Œæœç´¢
        distances, indices = index.search(np.array([query_vector]), k)
        
        print("ğŸ¯ æœç´¢ç»“æœ:")
        print("-" * 50)
        for i, (idx, dist) in enumerate(zip(indices[0], distances[0])):
            print(f"{i+1}. {texts[idx]}")
            print(f"   ç›¸ä¼¼åº¦åˆ†æ•°: {dist:.2f}")
            print()
            
        return indices[0], distances[0]

def demo_basic_usage():
    """åŸºç¡€ä½¿ç”¨æ¼”ç¤º"""
    print("=" * 60)
    print("ğŸ“š å‘é‡æ•°æ®åº“åŸºç¡€ä½¿ç”¨æ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºæ¼”ç¤ºå®ä¾‹
    demo = VectorDBDemo()
    
    # ç¤ºä¾‹æ–‡æœ¬æ•°æ®
    sample_texts = [
        "äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œ",
        "æœºå™¨å­¦ä¹ æ˜¯AIçš„æ ¸å¿ƒæŠ€æœ¯",
        "æ·±åº¦å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«ä¸­è¡¨ç°å‡ºè‰²",
        "è‡ªç„¶è¯­è¨€å¤„ç†è®©è®¡ç®—æœºç†è§£äººç±»è¯­è¨€",
        "Pythonæ˜¯æ•°æ®ç§‘å­¦çš„é¦–é€‰è¯­è¨€",
        "ä»Šå¤©å¤©æ°”çœŸå¥½",
        "æˆ‘å–œæ¬¢åƒè‹¹æœ",
        "çº¢å¯Œå£«æ˜¯ä¸€ç§ä¼˜è´¨çš„è‹¹æœå“ç§"
    ]
    
    # è½¬æ¢ä¸ºå‘é‡
    vectors = demo.text_to_vectors(sample_texts)
    
    # åˆ›å»ºå‘é‡æ•°æ®åº“
    vector_db = demo.create_vector_db(vectors)
    
    # æ‰§è¡Œæœç´¢
    queries = [
        "AIæŠ€æœ¯çš„å‘å±•",
        "æ°´æœç›¸å…³çš„è¯æ±‡",
        "ç¼–ç¨‹è¯­è¨€ä»‹ç»"
    ]
    
    for query in queries:
        demo.search_similar(vector_db, query, sample_texts)
        print("=" * 50)

def demo_similarity_calculation():
    """ç›¸ä¼¼åº¦è®¡ç®—æ¼”ç¤º"""
    print("\n" + "=" * 60)
    print("ğŸ“ æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—æ¼”ç¤º")
    print("=" * 60)
    
    demo = VectorDBDemo()
    
    # è®¡ç®—ä¸¤ä¸¤ä¹‹é—´çš„ç›¸ä¼¼åº¦
    texts = [
        "æˆ‘å–œæ¬¢ç¼–ç¨‹",
        "æˆ‘çƒ­çˆ±å†™ä»£ç ", 
        "ä»Šå¤©å¤©æ°”ä¸é”™",
        "ä»Šæ—¥æ™´æœ—æ— äº‘"
    ]
    
    vectors = demo.text_to_vectors(texts)
    
    print("\nğŸ”„ è®¡ç®—æ–‡æœ¬é—´çš„ç›¸ä¼¼åº¦:")
    print("-" * 40)
    
    # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    for i in range(len(texts)):
        for j in range(i+1, len(texts)):
            # ä½™å¼¦ç›¸ä¼¼åº¦å…¬å¼
            similarity = np.dot(vectors[i], vectors[j]) / \
                        (np.linalg.norm(vectors[i]) * np.linalg.norm(vectors[j]))
            
            print(f"'{texts[i]}' vs '{texts[j]}': {similarity:.3f}")

def demo_practical_application():
    """å®é™…åº”ç”¨åœºæ™¯æ¼”ç¤º"""
    print("\n" + "=" * 60)
    print("ğŸ’¼ å®é™…åº”ç”¨åœºæ™¯ï¼šç®€æ˜“é—®ç­”ç³»ç»Ÿ")
    print("=" * 60)
    
    # çŸ¥è¯†åº“
    knowledge_base = [
        "Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œè¯­æ³•ç®€æ´æ˜“å­¦",
        "Javaæ˜¯ä¸€ç§é¢å‘å¯¹è±¡çš„ç¼–ç¨‹è¯­è¨€ï¼Œè·¨å¹³å°æ€§å¼º",
        "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯",
        "æœºå™¨å­¦ä¹ æ˜¯å®ç°äººå·¥æ™ºèƒ½çš„ä¸€ç§æ–¹æ³•",
        "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸ",
        "TensorFlowæ˜¯ä¸€ä¸ªæµè¡Œçš„æœºå™¨å­¦ä¹ æ¡†æ¶",
        "PyTorchæ˜¯å¦ä¸€ä¸ªä¼˜ç§€çš„æ·±åº¦å­¦ä¹ æ¡†æ¶"
    ]
    
    demo = VectorDBDemo()
    vectors = demo.text_to_vectors(knowledge_base)
    vector_db = demo.create_vector_db(vectors)
    
    # é—®ç­”ç³»ç»Ÿ
    def simple_qa_system(question):
        print(f"\nâ“ é—®é¢˜: {question}")
        indices, distances = demo.search_similar(vector_db, question, knowledge_base, k=1)
        answer = knowledge_base[indices[0]]
        print(f"ğŸ’¡ å›ç­”: {answer}")
        return answer
    
    # æµ‹è¯•é—®é¢˜
    questions = [
        "ä»€ä¹ˆæ˜¯Pythonï¼Ÿ",
        "AIæ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ",
        "æœ‰å“ªäº›æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Ÿ"
    ]
    
    for question in questions:
        simple_qa_system(question)

def performance_comparison():
    """æ€§èƒ½å¯¹æ¯”æ¼”ç¤º"""
    print("\n" + "=" * 60)
    print("âš¡ æ€§èƒ½å¯¹æ¯”æµ‹è¯•")
    print("=" * 60)
    
    import random
    import string
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    def generate_random_text(length=10):
        return ''.join(random.choices(string.ascii_letters + ' ', k=length))
    
    # ä¸åŒè§„æ¨¡çš„æµ‹è¯•
    sizes = [100, 500, 1000]
    
    for size in sizes:
        print(f"\nğŸ“Š æµ‹è¯•è§„æ¨¡: {size} æ¡æ–‡æœ¬")
        texts = [generate_random_text() for _ in range(size)]
        
        demo = VectorDBDemo()
        
        # è®¡æ—¶
        start_time = time.time()
        vectors = demo.text_to_vectors(texts)
        encoding_time = time.time() - start_time
        
        start_time = time.time()
        vector_db = demo.create_vector_db(vectors)
        indexing_time = time.time() - start_time
        
        start_time = time.time()
        demo.search_similar(vector_db, "æµ‹è¯•æŸ¥è¯¢", texts, k=5)
        search_time = time.time() - start_time
        
        print(f"â±ï¸  ç¼–ç æ—¶é—´: {encoding_time:.2f}ç§’")
        print(f"â±ï¸  ç´¢å¼•æ—¶é—´: {indexing_time:.2f}ç§’") 
        print(f"â±ï¸  æŸ¥è¯¢æ—¶é—´: {search_time:.4f}ç§’")

if __name__ == "__main__":
    print("ğŸ“ æ¬¢è¿å­¦ä¹ å‘é‡æ•°æ®åº“å’ŒåµŒå…¥æ¨¡å‹ï¼")
    print("è¿™ä¸ªæ¼”ç¤ºå°†å±•ç¤ºæ ¸å¿ƒæ¦‚å¿µå’Œå®é™…åº”ç”¨")
    
    # è¿è¡Œæ‰€æœ‰æ¼”ç¤º
    demo_basic_usage()
    demo_similarity_calculation() 
    demo_practical_application()
    performance_comparison()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æ¼”ç¤ºå®Œæˆï¼")
    print("ç°åœ¨ä½ å¯ä»¥å°è¯•ä¿®æ”¹ä»£ç æ¥æ¢ç´¢æ›´å¤šåŠŸèƒ½")
    print("=" * 60)