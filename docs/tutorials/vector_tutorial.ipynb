{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“ å‘é‡æ•°æ®åº“äº’åŠ¨æ•™ç¨‹\n",
    "\n",
    "è¿™æ˜¯ä¸€ä¸ªäº¤äº’å¼çš„å‘é‡æ•°æ®åº“å­¦ä¹ ç¬”è®°æœ¬ã€‚ä½ å¯ä»¥é€ä¸ªè¿è¡Œå•å…ƒæ ¼æ¥å­¦ä¹ æ¦‚å¿µã€‚\n",
    "\n",
    "**å­¦ä¹ ç›®æ ‡ï¼š**\n",
    "- ç†è§£åµŒå…¥æ¨¡å‹çš„å·¥ä½œåŸç†\n",
    "- æŒæ¡å‘é‡æ•°æ®åº“çš„åŸºæœ¬æ“ä½œ\n",
    "- æ„å»ºç®€å•çš„è¯­ä¹‰æœç´¢åº”ç”¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ ç¯å¢ƒè®¾ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…å¿…è¦ä¾èµ–\n",
    "!pip install sentence-transformers faiss-cpu numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import time\n",
    "\n",
    "print(\"âœ… ç¯å¢ƒè®¾ç½®å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§  ç¬¬ä¸€æ­¥ï¼šç†è§£åµŒå…¥æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½é¢„è®­ç»ƒçš„åµŒå…¥æ¨¡å‹\n",
    "print(\"ğŸš€ åŠ è½½åµŒå…¥æ¨¡å‹...\")\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "print(\"âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# çœ‹çœ‹æ–‡æœ¬æ˜¯å¦‚ä½•å˜æˆæ•°å­—çš„\n",
    "sample_text = \"äººå·¥æ™ºèƒ½å¾ˆæœ‰è¶£\"\n",
    "embedding = model.encode([sample_text])[0]\n",
    "\n",
    "print(f\"åŸæ–‡æœ¬: {sample_text}\")\n",
    "print(f\"å‘é‡ç»´åº¦: {len(embedding)}\")\n",
    "print(f\"å‰10ä¸ªæ•°å€¼: {embedding[:10]}\")\n",
    "print(f\"æ•°å€¼èŒƒå›´: {embedding.min():.3f} åˆ° {embedding.max():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¯”è¾ƒä¸åŒæ–‡æœ¬çš„ç›¸ä¼¼åº¦\n",
    "texts = [\n",
    "    \"æˆ‘å–œæ¬¢ç¼–ç¨‹\",\n",
    "    \"æˆ‘çƒ­çˆ±å†™ä»£ç \", \n",
    "    \"ä»Šå¤©å¤©æ°”å¾ˆå¥½\",\n",
    "    \"ä»Šæ—¥é˜³å…‰æ˜åªš\"\n",
    "]\n",
    "\n",
    "embeddings = model.encode(texts)\n",
    "\n",
    "# è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ\n",
    "print(\"ğŸ“ æ–‡æœ¬ç›¸ä¼¼åº¦çŸ©é˜µ:\")\n",
    "print(\"\\næ–‡æœ¬åˆ—è¡¨:\")\n",
    "for i, text in enumerate(texts):\n",
    "    print(f\"{i+1}. {text}\")\n",
    "\n",
    "print(\"\\nç›¸ä¼¼åº¦åˆ†æ•° (è¶Šæ¥è¿‘1è¶Šç›¸ä¼¼):\")\n",
    "print(\"     \", end=\"\")\n",
    "for i in range(len(texts)):\n",
    "    print(f\"  [{i+1}]\", end=\"\")\n",
    "print()\n",
    "\n",
    "for i in range(len(texts)):\n",
    "    print(f\"[{i+1}]  \", end=\"\")\n",
    "    for j in range(len(texts)):\n",
    "        # ä½™å¼¦ç›¸ä¼¼åº¦\n",
    "        similarity = np.dot(embeddings[i], embeddings[j]) / \\\n",
    "                    (np.linalg.norm(embeddings[i]) * np.linalg.norm(embeddings[j]))\n",
    "        print(f\"{similarity:.2f} \", end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—„ï¸ ç¬¬äºŒæ­¥ï¼šæ„å»ºå‘é‡æ•°æ®åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºç¤ºä¾‹æ•°æ®é›†\n",
    "knowledge_base = [\n",
    "    \"Pythonæ˜¯ä¸€ç§è§£é‡Šå‹ã€é¢å‘å¯¹è±¡çš„ç¼–ç¨‹è¯­è¨€\",\n",
    "    \"Javaæ˜¯ä¸€ç§è·¨å¹³å°çš„é¢å‘å¯¹è±¡ç¼–ç¨‹è¯­è¨€\",\n",
    "    \"äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯é¢†åŸŸ\",\n",
    "    \"æœºå™¨å­¦ä¹ æ˜¯å®ç°äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒæŠ€æœ¯ä¹‹ä¸€\",\n",
    "    \"æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªé‡è¦å­é¢†åŸŸ\",\n",
    "    \"TensorFlowæ˜¯ç”±Googleå¼€å‘çš„æœºå™¨å­¦ä¹ æ¡†æ¶\",\n",
    "    \"PyTorchæ˜¯Facebookå¼€å‘çš„æ·±åº¦å­¦ä¹ æ¡†æ¶\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ“š çŸ¥è¯†åº“å†…å®¹:\")\n",
    "for i, item in enumerate(knowledge_base):\n",
    "    print(f\"{i+1}. {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°†çŸ¥è¯†åº“è½¬æ¢ä¸ºå‘é‡\n",
    "print(\"ğŸ”„ å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡...\")\n",
    "start_time = time.time()\n",
    "knowledge_vectors = model.encode(knowledge_base)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"âœ… è½¬æ¢å®Œæˆï¼è€—æ—¶: {end_time - start_time:.2f} ç§’\")\n",
    "print(f\"ğŸ“Š å‘é‡å½¢çŠ¶: {knowledge_vectors.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºFAISSå‘é‡æ•°æ®åº“\n",
    "dimension = knowledge_vectors.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "print(f\"ğŸ—ï¸ åˆ›å»º {dimension} ç»´çš„å‘é‡ç´¢å¼•...\")\n",
    "index.add(knowledge_vectors)\n",
    "print(f\"âœ… å‘é‡æ•°æ®åº“åˆ›å»ºå®Œæˆï¼ŒåŒ…å« {index.ntotal} æ¡è®°å½•\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” ç¬¬ä¸‰æ­¥ï¼šæ‰§è¡Œè¯­ä¹‰æœç´¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰æœç´¢å‡½æ•°\n",
    "def semantic_search(query, k=3):\n",
    "    \"\"\"æ‰§è¡Œè¯­ä¹‰æœç´¢\"\"\"\n",
    "    print(f\"\\nğŸ” æŸ¥è¯¢: \\\"{query}\\\"\")\n",
    "    \n",
    "    # å°†æŸ¥è¯¢è½¬æ¢ä¸ºå‘é‡\n",
    "    query_vector = model.encode([query])\n",
    "    \n",
    "    # æ‰§è¡Œæœç´¢\n",
    "    distances, indices = index.search(query_vector, k)\n",
    "    \n",
    "    print(\"\\nğŸ¯ æœç´¢ç»“æœ:\")\n",
    "    print(\"-\" * 50)\n",
    "    for i, (idx, dist) in enumerate(zip(indices[0], distances[0])):\n",
    "        print(f\"{i+1}. {knowledge_base[idx]}\")\n",
    "        print(f\"   ç›¸ä¼¼åº¦åˆ†æ•°: {dist:.2f}\")\n",
    "        print()\n",
    "    \n",
    "    return indices[0], distances[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•ä¸åŒçš„æŸ¥è¯¢\n",
    "queries = [\n",
    "    \"ä»€ä¹ˆæ˜¯Pythonï¼Ÿ\",\n",
    "    \"AIæŠ€æœ¯ä»‹ç»\",\n",
    "    \"æ·±åº¦å­¦ä¹ æ¡†æ¶æœ‰å“ªäº›ï¼Ÿ\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    semantic_search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š ç¬¬å››æ­¥ï¼šå¯è§†åŒ–å‘é‡ç©ºé—´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨t-SNEé™ç»´è¿›è¡Œå¯è§†åŒ–\n",
    "print(\"ğŸ¨ é™ç»´å¤„ç†ä¸­...\")\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(knowledge_base)-1))\n",
    "vectors_2d = tsne.fit_transform(knowledge_vectors)\n",
    "\n",
    "print(\"âœ… é™ç»´å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºå¯è§†åŒ–å›¾è¡¨\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# ç»˜åˆ¶ç‚¹\n",
    "scatter = plt.scatter(vectors_2d[:, 0], vectors_2d[:, 1], \n",
    "                     c=range(len(knowledge_base)), \n",
    "                     cmap='viridis', \n",
    "                     alpha=0.7,\n",
    "                     s=100)\n",
    "\n",
    "# æ·»åŠ æ ‡ç­¾\n",
    "for i, (x, y) in enumerate(vectors_2d):\n",
    "    plt.annotate(f'{i+1}', (x, y), xytext=(5, 5), \n",
    "                textcoords='offset points', fontsize=10,\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7))\n",
    "\n",
    "plt.title('çŸ¥è¯†åº“å‘é‡ç©ºé—´å¯è§†åŒ– (t-SNE)', fontsize=16)\n",
    "plt.xlabel('ç¬¬ä¸€ä¸»æˆåˆ†')\n",
    "plt.ylabel('ç¬¬äºŒä¸»æˆåˆ†')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# æ·»åŠ å›¾ä¾‹\n",
    "legend_elements = [plt.Line2D([0], [0], marker='o', color='w', \n",
    "                             markerfacecolor=plt.cm.viridis(i/len(knowledge_base)), \n",
    "                             markersize=10, label=f'{i+1}. {text[:30]}...') \n",
    "                   for i, text in enumerate(knowledge_base)]\n",
    "\n",
    "plt.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ç¬¬äº”æ­¥ï¼šæ„å»ºç®€æ˜“é—®ç­”ç³»ç»Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºé—®ç­”ç³»ç»Ÿç±»\n",
    "class SimpleQASystem:\n",
    "    def __init__(self, knowledge_base):\n",
    "        self.knowledge_base = knowledge_base\n",
    "        self.model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "        self.vectors = self.model.encode(knowledge_base)\n",
    "        \n",
    "        # åˆ›å»ºå‘é‡æ•°æ®åº“\n",
    "        dimension = self.vectors.shape[1]\n",
    "        self.index = faiss.IndexFlatL2(dimension)\n",
    "        self.index.add(self.vectors)\n",
    "        \n",
    "        print(\"âœ… é—®ç­”ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼\")\n",
    "    \n",
    "    def answer(self, question, k=1):\n",
    "        \"\"\"å›ç­”é—®é¢˜\"\"\"\n",
    "        # è½¬æ¢é—®é¢˜ä¸ºå‘é‡\n",
    "        question_vector = self.model.encode([question])\n",
    "        \n",
    "        # æœç´¢æœ€ç›¸ä¼¼çš„çŸ¥è¯†\n",
    "        distances, indices = self.index.search(question_vector, k)\n",
    "        \n",
    "        # è¿”å›ç­”æ¡ˆ\n",
    "        answers = []\n",
    "        for idx, dist in zip(indices[0], distances[0]):\n",
    "            answers.append({\n",
    "                'answer': self.knowledge_base[idx],\n",
    "                'confidence': 1/(1 + dist),  # ç®€å•çš„ç½®ä¿¡åº¦è®¡ç®—\n",
    "                'similarity_score': dist\n",
    "            })\n",
    "        \n",
    "        return answers[0] if len(answers) == 1 else answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•é—®ç­”ç³»ç»Ÿ\n",
    "qa_system = SimpleQASystem(knowledge_base)\n",
    "\n",
    "test_questions = [\n",
    "    \"Pythonæ˜¯ä»€ä¹ˆï¼Ÿ\",\n",
    "    \"ä»‹ç»ä¸€ä¸‹AI\",\n",
    "    \"æœ‰å“ªäº›æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Ÿ\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ¤– é—®ç­”ç³»ç»Ÿæµ‹è¯•:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for question in test_questions:\n",
    "    result = qa_system.answer(question)\n",
    "    print(f\"\\nâ“ é—®: {question}\")\n",
    "    print(f\"ğŸ’¡ ç­”: {result['answer']}\")\n",
    "    print(f\"ğŸ“Š ç½®ä¿¡åº¦: {result['confidence']:.3f}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ æ‰©å±•ç»ƒä¹ \n",
    "\n",
    "ç°åœ¨è½®åˆ°ä½ æ¥å°è¯•äº†ï¼ä¿®æ”¹ä¸‹é¢çš„ä»£ç ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: åˆ›å»ºä½ è‡ªå·±çš„çŸ¥è¯†åº“\n",
    "my_knowledge_base = [\n",
    "    # åœ¨è¿™é‡Œæ·»åŠ ä½ æ„Ÿå…´è¶£çš„ä¸»é¢˜\n",
    "    \"åœ¨è¿™é‡Œå†™ä¸‹ä½ çš„ç¬¬ä¸€æ¡çŸ¥è¯†...\",\n",
    "    \"åœ¨è¿™é‡Œå†™ä¸‹ä½ çš„ç¬¬äºŒæ¡çŸ¥è¯†...\",\n",
    "    # æ·»åŠ æ›´å¤š...\n",
    "]\n",
    "\n",
    "# TODO: åˆ›å»ºä½ è‡ªå·±çš„é—®ç­”ç³»ç»Ÿ\n",
    "# my_qa_system = SimpleQASystem(my_knowledge_base)\n",
    "\n",
    "# TODO: æµ‹è¯•ä½ çš„ç³»ç»Ÿ\n",
    "# my_questions = [\"ä½ çš„é—®é¢˜1\", \"ä½ çš„é—®é¢˜2\"]\n",
    "# for q in my_questions:\n",
    "#     result = my_qa_system.answer(q)\n",
    "#     print(f\"é—®: {q}\")\n",
    "#     print(f\"ç­”: {result['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š æ€»ç»“\n",
    "\n",
    "æ­å–œå®Œæˆæœ¬æ¬¡å­¦ä¹ ï¼ä½ ç°åœ¨å·²ç»æŒæ¡äº†ï¼š\n",
    "\n",
    "âœ… åµŒå…¥æ¨¡å‹çš„åŸºæœ¬åŸç†\n",
    "âœ… å‘é‡æ•°æ®åº“çš„åˆ›å»ºå’Œä½¿ç”¨\n",
    "âœ… è¯­ä¹‰æœç´¢çš„å®ç°\n",
    "âœ… ç®€æ˜“é—®ç­”ç³»ç»Ÿçš„æ„å»º\n",
    "\n",
    "**ä¸‹ä¸€æ­¥å»ºè®®ï¼š**\n",
    "1. å°è¯•ä¸åŒçš„åµŒå…¥æ¨¡å‹\n",
    "2. ä½¿ç”¨æ›´å¤§çš„æ•°æ®é›†\n",
    "3. æ¢ç´¢å…¶ä»–å‘é‡æ•°æ®åº“ï¼ˆå¦‚ Weaviateã€Milvusï¼‰\n",
    "4. æ·»åŠ æ›´å¤šçš„é¢„å¤„ç†å’Œåå¤„ç†åŠŸèƒ½"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}