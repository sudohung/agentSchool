# æœ¬åœ°æ¨¡å‹è·¯å¾„é…ç½®ä½¿ç”¨è¯´æ˜

## ğŸ¯ æœ¬åœ°æ¨¡å‹è·¯å¾„é…ç½®æ–¹æ³•

### 1. é…ç½®æ–‡ä»¶ç»“æ„

```json
{
  "device": "nv_gpu",
  "cpu": {
    "backend": "sentence_transformers",
    "model_name": "sentence-transformers/all-MiniLM-L6-v2",
    "model_path": "/path/to/local/model",  // æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    "dim": 384
  },
  "nv_gpu": {
    "gpu_id": 0,
    "backend": "sentence_transformers",
    "model_name": "sentence-transformers/all-MiniLM-L6-v2",
    "model_path": "C:\\Users\\hung\\Desktop\\workspace\\modelscope\\bge-m3",  // æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
    "dim": 1024
  }
}
```

### 2. é…ç½®ä¼˜å…ˆçº§è¯´æ˜

ç³»ç»Ÿä¼šæŒ‰ç…§ä»¥ä¸‹ä¼˜å…ˆçº§åŠ è½½æ¨¡å‹ï¼š

1. **æœ€é«˜ä¼˜å…ˆçº§**ï¼š`model_path` - æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼ˆå¦‚æœè·¯å¾„å­˜åœ¨ï¼‰
2. **å¤‡é€‰æ–¹æ¡ˆ**ï¼š`model_name` - HuggingFaceæ¨¡å‹åç§°ï¼ˆåœ¨çº¿ä¸‹è½½ï¼‰

### 3. æœ¬åœ°æ¨¡å‹è·¯å¾„é…ç½®ç¤ºä¾‹

#### CPUæ¨¡å¼é…ç½®
```json
{
  "device": "cpu",
  "cpu": {
    "model_path": "/home/user/models/all-MiniLM-L6-v2",
    "dim": 384
  }
}
```

#### NVIDIA GPUæ¨¡å¼é…ç½®
```json
{
  "device": "nv_gpu",
  "nv_gpu": {
    "gpu_id": 0,
    "model_path": "D:\\models\\bge-large-zh-v1.5",
    "dim": 1024
  }
}
```

#### AMD GPUæ¨¡å¼é…ç½®ï¼ˆONNXæ¨¡å‹ï¼‰
```json
{
  "device": "gpu",
  "gpu": {
    "onnx_path": "./models/model.onnx",
    "tokenizer": "BAAI/bge-base-zh-v1.5",
    "dim": 768
  }
}
```

## ğŸ“ æœ¬åœ°æ¨¡å‹ç›®å½•ç»“æ„

### SentenceTransformeræ¨¡å‹ç›®å½•ç»“æ„
```
your-local-model/
â”œâ”€â”€ config.json
â”œâ”€â”€ modules.json
â”œâ”€â”€ config_sentence_transformers.json
â”œâ”€â”€ 1_Pooling/
â”‚   â””â”€â”€ config.json
â”œâ”€â”€ 2_Dense/
â”‚   â””â”€â”€ config.json
â”œâ”€â”€ pytorch_model.bin
â”œâ”€â”€ sentence_bert_config.json
â””â”€â”€ tokenizer.json
```

### ä¸‹è½½æœ¬åœ°æ¨¡å‹çš„æ–¹æ³•

#### æ–¹æ³•1ï¼šä½¿ç”¨transformers-cliä¸‹è½½
```bash
# å®‰è£…transformers
pip install transformers

# ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°
python -c "
from transformers import AutoModel, AutoTokenizer
model_name = 'sentence-transformers/all-MiniLM-L6-v2'
model = AutoModel.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)
# ä¿å­˜åˆ°æœ¬åœ°
model.save_pretrained('./local_models/all-MiniLM-L6-v2')
tokenizer.save_pretrained('./local_models/all-MiniLM-L6-v2')
"
```

#### æ–¹æ³•2ï¼šä½¿ç”¨huggingface-hubä¸‹è½½
```bash
pip install huggingface-hub

# å‘½ä»¤è¡Œä¸‹è½½
huggingface-cli download sentence-transformers/all-MiniLM-L6-v2 --local-dir ./models/all-MiniLM-L6-v2
```

#### æ–¹æ³•3ï¼šæ‰‹åŠ¨ä¸‹è½½
1. è®¿é—®[HuggingFace Models](https://huggingface.co/models)
2. æœç´¢éœ€è¦çš„æ¨¡å‹
3. ç‚¹å‡»"Files and versions"
4. ä¸‹è½½æ‰€æœ‰æ–‡ä»¶åˆ°æœ¬åœ°ç›®å½•

## ğŸ” éªŒè¯æœ¬åœ°æ¨¡å‹é…ç½®

### 1. æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦å­˜åœ¨
```python
import os
model_path = "C:\\Users\\hung\\Desktop\\workspace\\modelscope\\bge-m3"
print(f"æ¨¡å‹è·¯å¾„å­˜åœ¨: {os.path.exists(model_path)}")
print(f"è·¯å¾„æ˜¯ç›®å½•: {os.path.isdir(model_path)}")
```

### 2. æµ‹è¯•æœ¬åœ°æ¨¡å‹åŠ è½½
```python
from sentence_transformers import SentenceTransformer

# æµ‹è¯•æœ¬åœ°æ¨¡å‹
try:
    model = SentenceTransformer("C:\\Users\\hung\\Desktop\\workspace\\modelscope\\bge-m3")
    print("âœ… æœ¬åœ°æ¨¡å‹åŠ è½½æˆåŠŸ")
    
    # æµ‹è¯•ç¼–ç 
    embeddings = model.encode(["æµ‹è¯•å¥å­"])
    print(f"åµŒå…¥ç»´åº¦: {embeddings.shape}")
    
except Exception as e:
    print(f"âŒ æœ¬åœ°æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
```

### 3. éªŒè¯é…ç½®æ–‡ä»¶
```python
import json

# è¯»å–å¹¶éªŒè¯é…ç½®
with open('embedder_config.json', 'r', encoding='utf-8') as f:
    config = json.load(f)

print("é…ç½®éªŒè¯:")
for device_key in ['cpu', 'nv_gpu', 'gpu']:
    if device_key in config:
        device_config = config[device_key]
        model_path = device_config.get('model_path')
        model_name = device_config.get('model_name')
        
        print(f"\n{device_key.upper()} é…ç½®:")
        if model_path:
            path_exists = os.path.exists(model_path) if model_path else False
            print(f"  æœ¬åœ°æ¨¡å‹è·¯å¾„: {model_path} ({'å­˜åœ¨' if path_exists else 'ä¸å­˜åœ¨'})")
        print(f"  åœ¨çº¿æ¨¡å‹åç§°: {model_name}")
```

## âš ï¸ å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

### é—®é¢˜1ï¼šè·¯å¾„æ ¼å¼é”™è¯¯
```json
// âŒ é”™è¯¯çš„è·¯å¾„æ ¼å¼
"model_path": "C:\Users\model"  // åæ–œæ éœ€è¦è½¬ä¹‰

// âœ… æ­£ç¡®çš„è·¯å¾„æ ¼å¼
"model_path": "C:\\Users\\model"  // åŒåæ–œæ 
// æˆ–
"model_path": "C:/Users/model"    // æ­£æ–œæ 
```

### é—®é¢˜2ï¼šæ¨¡å‹æ–‡ä»¶ä¸å®Œæ•´
```bash
# æ£€æŸ¥å¿…è¦æ–‡ä»¶
required_files = ['config.json', 'pytorch_model.bin', 'tokenizer.json']
model_dir = "your/model/path"

missing_files = [f for f in required_files if not os.path.exists(os.path.join(model_dir, f))]
if missing_files:
    print(f"ç¼ºå°‘æ–‡ä»¶: {missing_files}")
```

### é—®é¢˜3ï¼šæƒé™é—®é¢˜
```bash
# ç¡®ä¿æœ‰è¶³å¤Ÿçš„è¯»å–æƒé™
import os
model_path = "/path/to/model"
if os.access(model_path, os.R_OK):
    print("æœ‰è¯»å–æƒé™")
else:
    print("æ— è¯»å–æƒé™ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æƒé™")
```

## ğŸš€ æœ€ä½³å®è·µå»ºè®®

### 1. æ¨¡å‹ç»„ç»‡ç»“æ„
```
models/
â”œâ”€â”€ sentence-transformers/
â”‚   â”œâ”€â”€ all-MiniLM-L6-v2/
â”‚   â”œâ”€â”€ all-mpnet-base-v2/
â”‚   â””â”€â”€ paraphrase-multilingual-MiniLM-L12-v2/
â”œâ”€â”€ bge/
â”‚   â”œâ”€â”€ bge-small-en-v1.5/
â”‚   â””â”€â”€ bge-large-zh-v1.5/
â””â”€â”€ indexes/
    â”œâ”€â”€ cpu/
    â”œâ”€â”€ gpu/
    â””â”€â”€ nv_gpu/
```

### 2. é…ç½®æ–‡ä»¶æ¨¡æ¿
```json
{
  "device": "nv_gpu",
  "cpu": {
    "model_path": "./models/sentence-transformers/all-MiniLM-L6-v2",
    "dim": 384
  },
  "nv_gpu": {
    "gpu_id": 0,
    "model_path": "./models/bge/bge-large-zh-v1.5",
    "dim": 1024
  },
  "faiss": {
    "nv_gpu": {
      "index_path": "./indexes/nv_gpu/faiss.index",
      "meta_path": "./indexes/nv_gpu/faiss_meta.json"
    }
  }
}
```

### 3. ç¯å¢ƒå˜é‡é…ç½®
```bash
# è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå¯é€‰ï¼‰
export LOCAL_MODEL_PATH="/path/to/models"
export FAISS_INDEX_PATH="./indexes"
```

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| é…ç½®æ–¹å¼ | åŠ è½½æ—¶é—´ | ç½‘ç»œä¾èµ– | é€‚ç”¨åœºæ™¯ |
|----------|----------|----------|----------|
| åœ¨çº¿æ¨¡å‹ | è¾ƒæ…¢ | éœ€è¦ | é¦–æ¬¡ä½¿ç”¨ã€ç½‘ç»œè‰¯å¥½ |
| æœ¬åœ°æ¨¡å‹ | å¿«é€Ÿ | ä¸éœ€è¦ | ç”Ÿäº§ç¯å¢ƒã€ç¦»çº¿éƒ¨ç½² |
| æ··åˆé…ç½® | ä¸­ç­‰ | å¤‡ç”¨ | å¼€å‘æµ‹è¯•ã€çµæ´»åˆ‡æ¢ |

ç°åœ¨ä½ å¯ä»¥é€šè¿‡é…ç½®`model_path`æ¥ä½¿ç”¨æœ¬åœ°æ¨¡å‹äº†ï¼ç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹è·¯å¾„æ˜¯å¦å­˜åœ¨ï¼Œå¹¶ä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹ä»¥æé«˜åŠ è½½é€Ÿåº¦å’Œå¯é æ€§ã€‚